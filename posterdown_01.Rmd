---
main_topsize: 0.2 #percent coverage of the poster
main_bottomsize: 0.1
#ESSENTIALS
title: "**An analysis of EPSM and AOCMP abstact submissions**"
author:
  - name: Robert Day
    affil: 1
  - name: Tegan Rourke
    affil: 2
  - name: Harriet Cottam
    affil: 3
affiliation:
  - num: 1
    address: Health Technology Management Unit, EMHS
  - num: 2
    address: Medical Technology & Physics, Sir Charles Gairdner Hospital
  - num: 3
    address: The Conference Company
main_findings:
  - "**EPSM** authors are as optimisitc as in 2013.<br>**AOCMP** authors are more punctual."
logoleft_name: ./images/EPSM-Conference-Logo-Suite-2019-02.png
logoright_name: https&#58;//raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png
# logocenter_name: https&#58;//github.com/yadbor/EPSM-analysis/raw/master/images/EPSM-analysis_2k_qr-code.png
logocenter_name: ./images/EPSM-analysis_2k_qr-code.png
# Page parameters
# poster_height: "48in"
# poster_width: "36in"
output: 
  posterdown::posterdown_betterport:
    self_contained: false
    pandoc_args: --mathjax
    number_sections: false
bibliography: packages.bib
link-citations: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      tidy = FALSE,
                      message = FALSE,
                      fig.align = 'center',
                      out.width = "100%")
options(knitr.table.format = "html") 
knitr::write_bib(c('posterdown', 'rmarkdown','pagedown'), 'packages.bib')
```

# The prologue...

When EPSM came to Perth in 2013 it looked like making a huge loss.

To save money, branch members did most of the work of handling submissions, scheduling and making the abstract book. 
Just like the old days. 
This gave us direct access to the submission data, so we Scienced it. 
What we saw was that people: 

 a) left their submission to the very last minute
 b) *definitely* expected a deadline extension
 c) still left their submission to the very last minute

Has anyone learned anything since then?

```{r prologue, include=FALSE}
# Load needed libraries and set file locations
library(data.table)
library(stringr)
library(ggplot2)

# Paths relative to the Project folder.
# If running code as standalone from the R folder, need to be ../data etc
raw_path <- "./data-raw"
clean_path <- "./data"
```

# shiny, happy data

This year's Conference The initial raw data contained information that could be used to identify individual papers or submitters. 
To protect everyone's secret identities, these data were scrubbed clean. 
In the process, they were rearranged into a single standard format for comparison between meetings. 
The technical term for this is *munging*.

Only sparkling clean pre-munged data are included in this project for your convenience.

```{r load clean}
# Read the significant dates and convert them all to days-before-conference,
# then rearrange to long format for easier plotting.
events <- fread(file.path(clean_path, "conf.dates.csv"))
# make a conference column that matches the other tables
events[, conference := paste(city, year, sep = "_")]


# The same information, converted to day prior to conference
event_days <- events[, lapply(.SD, 
                              function(x) as.integer(difftime(x, date))
                              ),
                     .SDcols = c("call", "close", "extended"), 
                     by="conference,year,city"]
# Add a key to make indexing faster and easier
setkey(event_days, conference)

# Calculate how long each period was
period <- event_days[, .(total    = call, 
                         initial  = call-close, 
                         extended = close-extended, 
                         waiting  = extended), 
                     by="conference,year,city"]

# Make conference an ordered factor so ggplot doesn't rearrange
period[, conference := factor(conference, period[order(year), ]$conference)]
# Convert to long for for plotting
period_long <- melt(period, 
                    measure.vars = c("initial", "extended", "waiting"), 
                    variable.name = "period",
                    value.name = "days"
                   )
# Add a key to make indexing faster and easier
setkey(period_long, conference)

# calculate how long each period was
days_allowed <- events[, .(total    = as.integer(difftime(call, date)),
                           initial  = as.integer(difftime(call, close)),
                           extended = as.integer(difftime(close, extended)),
                           waiting  = as.integer(difftime(extended, date))
                           ), 
                           by="conference,year,city"
                       ]
# Make conference an ordered factor so ggplot doesn't rearrange
days_allowed[, conference := factor(conference, levels = rev(conference))]
# convert to long for for plotting
days_long <- melt(days_allowed, 
                  measure.vars = c("initial", "extended", "waiting"), 
                  variable.name = "period",
                  value.name = "days"
                  )

#Finally, load the submission days for all the conferences into a unified format.
sub_file_names <- file.path(clean_path, paste0(events[, conference], ".csv"))
#sub_files[, filename := file.path(clean_path, paste0(conference, ".csv"))]
SUBS <- data.table::data.table(conference = events[, conference],
                               filename   = sub_file_names)
SUBS <- SUBS[, fread(filename, col.names = c("day", "n")), by=conference]

# A wild kludge appears
SUBS[, day := -1 * day]

# Add a key to make indexing faster and easier
setkey(SUBS, conference)
# Calcuate the total number of submissions up to each day
SUBS[, sum := cumsum(n[order(day)]), by=conference]
# Make a meeting column as a factor with the order we define
SUBS[, meeting := factor(conference, levels= events[order(year), conference]) ]

# Classify the submissions into 
# 
#   * premature -- before call for papers
#   * early -- before the close 
#   * lucky -- after the first close but before the extention period ends
#   * late -- after the extended period closes (won't be any of those, right?)

SUBS[day < event_days[conference, close], status := 'early', by=conference]
SUBS[day < event_days[conference, call], status := 'premature', by=conference]
SUBS[day > event_days[conference, extended], status := 'late', by=conference]
# The only un-lablled statuses must be the lucky ones
SUBS[is.na(status), status := "lucky"]
# Make the status a factor and put in temporal order
SUBS[, status := factor(status, levels = c("premature", "early", "lucky", "late"))]

```

# Results
```{r fig.cap='Time allowed for submissions by conference', out.width="80%"}
# Use a colourblind friendly palette with grey
ggplot(days_long) + 
  aes(x = conference, y = days, fill = period) +
  geom_col(width = 0.5) +
  scale_fill_manual(name = "Submission\nPeriod",
                    breaks = c("initial", "extended"), 
                    values=c("#56B4E9", "#E69F00", NA)) +
  geom_hline(yintercept = 0, colour = "black") +
  geom_vline(xintercept = 3.5, linetype = 2, size = 0.1) +
  ylab("days before meeting") +
  theme(legend.position=c(.80, .8)) +
  coord_flip()

```

EPSM conferences vary in the length of time they allow for submitting abstracts, 
although they all call for papers about `r round(abs(days_allowed[, mean(total)]), -1)` days before the conference.
Perth 2013 opened earlier and for longer, 
with an extension period twice that of other conferences.
This was done to maximise the number of ~~income generating units~~ attendees.

There were plenty of papers at each conference. 
```{r}
# How many papers in each status group, by conference
tbl <- dcast(SUBS, value.var = "n", conference~status, fun = sum)
# and add the sum of all papers, per conference
tbl[, total:=base::sum(.SD), by=conference]
# make in year order
tbl <- tbl[order(-str_extract(conference, "_(.*)")),] 
#print(tbl[, total, by=conference])

knitr::kable(
  tbl, format = "html",
  caption = "Submissions per conference.",
  align = c("l","r","r","r", "r"),
  escape = FALSE)
```
Perth 2019 is a monster with the assistance of AOCMP, weighing in at `r tbl[conference %like% 2019, sum(total)]` papers in total.

Hobart in 2017 looks a bit light on, but this may be due to some late submissions 
being missed[^1^].


AOCMP authors appear to be good at keeping to deadlines, with 2/3 of submissions in before the advertised close, and no late submissions.
```{r }
tbl_percent <- tbl[, lapply(.SD, function(x) round(100 * x / total, 1)),
                   by = conference]
tbl_long <- melt(tbl_percent[, -"total"], id.vars = "conference")
tbl_long[, variable := factor(variable, levels = c("late", "lucky", "early"))]
ggplot(tbl_long) + 
         aes(x=conference, y = value, fill = variable) + 
         geom_col()

```

By contrast EPSM authors like to live dangerously, with 
`r round(tbl_percent[conference != "AOCMP_2019", mean(lucky)], 1)`% 
of submissions in the extension period on average.

# what themes abounded?

Only the Perth meetings have submission details, which were grouped by broad themes for comparison.
```{r }
details <- data.table(file = dir(path = clean_path, 
                                 pattern = "details.csv", 
                                 full.names = TRUE)
)
details[, year := str_match(file, "\\_(\\d{4})\\_")[,2]]
col_types = list(character = 2:6, integer = 1)
PER <- details[, fread(file, colClasses = col_types), by=year]

# Make some broad classes of submission, based on which theme was chosen
PER[theme %like% "Radiology", topic := "Radiology"]
PER[theme %like% "ROMP|Radiotherapy", topic := "ROMP"]
PER[theme %like% "Nuclear Med", topic := "Nuc Med"]
PER[theme %like% "Health Phys", topic := "Health Phys"]
PER[theme %like% "Engineer", topic := "Eng"]
# A catch-all for the rest
PER[is.na(topic), topic := "other"]
# Two conferences in Perth this year, so label by meeting to tell them apart
PER[, meeting := paste(conference, year)]

# Calculate percentages by first getting the total count per meeting
# then dividing the count per topic by that total
numbers <- PER[, .N, by = "topic,meeting"]
numbers <- numbers[, .(topic, percent = 100*(N/sum(N))), by=meeting]

ggplot(numbers) + aes(x = meeting, y = percent, fill = topic) + geom_col()
```

The share of abstracts in each discipline seems fairly stable over time, although EPSM 2013 had more ROMP and Engineering related content and less Nuclear Medcine or Health Physics. The high number in Engineering may have been because Engineers on the conference committee actively extorted submissions.
```{r }
print(dcast(numbers, topic~meeting)[, lapply(.SD, round, 2), by = topic])
```

AOCMP members seem less interested in Radiology Physics, with a lot more 'other' abstracts.
This may be partly an artefact of the wide range of themes in 2019.

No-one seems to love Health Physics, which is sad.

# embrace & extend

This poster was made in an attempt to sell the idea of Reproduceable Research.

The complete package, including the cleaned data, code and the poster template will be at (https://github.com/yadbor/EPSM-analysis), or just scan the QR code on this poster.

# References
[^1^]: Rourke, T. 2019 Personal communication.

# Colophon
Made with the `posterdown_betterport` template for the {posterdown} package, available from CRAN (https://cran.r-project.org/) or github (https://github.com/brentthorne/posterdown). 

Written in R (https://www.r-project.org) and Rmarkdown (https://rmarkdown.rstudio.com), using RStudio 1.1.463 (https://rstudio.com)
