---
main_topsize: 0.2 #percent coverage of the poster
main_bottomsize: 0.1
#ESSENTIALS
title: "**An analysis of EPSM and AOCMP abstact submissions**"
author:
  - name: Robert Day
    affil: 1
  - name: Tegan Rourke
    affil: 2
  - name: Hilary Cottam
    affil: 3
affiliation:
  - num: 1
    address: Health Technology Management Unit, EMHS
  - num: 2
    address: Medical Technology & Physics, Sir Charles Gairdner Hospital
  - num: 3
    address: The Conference Company
main_findings:
  - "**EPSM** authors are just as optimisitc as in 2013.<br>**AOCMP** authors are more punctual."
logoleft_name: https&#58;//raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png
logoright_name: https&#58;//raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png
# logocenter_name: https&#58;//github.com/yadbor/EPSM-analysis/raw/master/images/EPSM-analysis_2k_qr-code.png
logocenter_name: ./images/EPSM-analysis_2k_qr-code.png
# Page parameters
# poster_height: "48in"
# poster_width: "36in"
output: 
  posterdown::posterdown_betterport:
    self_contained: false
    pandoc_args: --mathjax
    number_sections: false
bibliography: packages.bib
link-citations: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      tidy = FALSE,
                      message = FALSE,
                      fig.align = 'center',
                      out.width = "100%")
options(knitr.table.format = "html") 
knitr::write_bib(c('posterdown', 'rmarkdown','pagedown'), 'packages.bib')
```

# The prologue...

When EPSM came to Perth in 2013 it looked like making a huge loss.

To save money, branch members did most of the work of handling submissions, scheduling and making the abstract book. 
Just like the old days. 
This gave us direct access to the submission data, so we Scienced it. 
What we saw was that people: 

 a) left their submission to the very last minute
 b) *definitely* expected a deadline extension
 c) still left their submission to the very last minute

Has anyone learned anything since then?

```{r prologue, include=FALSE}
# Load needed libraries and set file locations
library(data.table)
library(stringr)
library(ggplot2)

# Paths relative to the Project folder.
# If running code as standalone from the R folder, need to be ../data etc
raw_path <- "./data-raw"
clean_path <- "./data"
```

# shiny, happy data

This year's Conference The initial raw data contained information that could be used to identify individual papers or submitters. 
To protect everyone's secret identities, these data were scrubbed clean. 
In the process, they were rearranged into a single standard format for comparison between meetings. 
The technical term for this is *munging*.
Only sparkling clean pre-munged data are included in this project for your convenience.

```{r load clean}
# Read the significant dates and convert them all to days-before-conference,
# then rearrange to long format for easier plotting.
events <- fread(file.path(clean_path, "conf.dates.csv"))
# make a conference column that matches the other tables
events[, conference := paste(city, year, sep = "_")]


# The same information, converted to day prior to conference
event_days <- events[, lapply(.SD, 
                              function(x) as.integer(difftime(x, date))
                              ),
                     .SDcols = c("call", "close", "extended"), 
                     by="conference,year,city"]
# Add a key to make indexing faster and easier
setkey(event_days, conference)

# Calculate how long each period was
period <- event_days[, .(total    = call, 
                         initial  = call-close, 
                         extended = close-extended, 
                         waiting  = extended), 
                     by="conference,year,city"]

# Make conference an ordered factor so ggplot doesn't rearrange
period[, conference := factor(conference, period[order(year), ]$conference)]
# Convert to long for for plotting
period_long <- melt(period, 
                    measure.vars = c("initial", "extended", "waiting"), 
                    variable.name = "period",
                    value.name = "days"
                   )
# Add a key to make indexing faster and easier
setkey(period_long, conference)

# calculate how long each period was
days_allowed <- events[, .(total    = as.integer(difftime(call, date)),
                           initial  = as.integer(difftime(call, close)),
                           extended = as.integer(difftime(close, extended)),
                           waiting  = as.integer(difftime(extended, date))
                           ), 
                           by="conference,year,city"
                       ]
# Make conference an ordered factor so ggplot doesn't rearrange
days_allowed[, conference := factor(conference, levels = rev(conference))]
# convert to long for for plotting
days_long <- melt(days_allowed, 
                  measure.vars = c("initial", "extended", "waiting"), 
                  variable.name = "period",
                  value.name = "days"
                  )

#Finally, load the submission days for all the conferences into a unified format.
sub_file_names <- file.path(clean_path, paste0(events[, conference], ".csv"))
#sub_files[, filename := file.path(clean_path, paste0(conference, ".csv"))]
SUBS <- data.table::data.table(conference = events[, conference],
                               filename   = sub_file_names)
SUBS <- SUBS[, fread(filename, col.names = c("day", "n")), by=conference]

# Add a key to make indexing faster and easier
setkey(SUBS, conference)
# Calcuate the total number of submissions up to each day
SUBS[, sum := cumsum(n[order(day)]), by=conference]
# Make a meeting column as a factor with the order we define
SUBS[, meeting := factor(conference, levels= events[order(year), conference]) ]

# Classify the submissions into 
# 
#   * premature -- before call for papers
#   * early -- before the close 
#   * lucky -- after the first close but before the extention period ends
#   * late -- after the extended period closes (won't be any of those, right?)

SUBS[day < event_days[conference, close], status := 'early', by=conference]
SUBS[day < event_days[conference, call], status := 'premature', by=conference]
SUBS[day > event_days[conference, extended], status := 'late', by=conference]
# The only un-lablled statuses must be the lucky ones
SUBS[is.na(status), status := "lucky"]
# Make the status a factor and put in temporal order
SUBS[, status := factor(status, levels = c("premature", "early", "lucky", "late"))]

```

# Results

```{r fig.cap='Time allowed for submissions by conference', out.width="80%"}
# Use a colourblind friendly palette with grey
ggplot(days_long) + 
  aes(x = conference, y = days, fill = period) +
  geom_col(width = 0.5) +
  scale_fill_manual(name = "Submission\nPeriod",
                    breaks = c("initial", "extended"), 
                    values=c("#56B4E9", "#E69F00", NA)) +
  geom_hline(yintercept = 0, colour = "black") +
  geom_vline(xintercept = 3.5, linetype = 2, size = 0.1) +
  ylab("days before meeting") +
  theme(legend.position=c(.80, .8)) +
  coord_flip()

```

EPSM conferences vary in the length of time they allow for submitting abstracts, 
although they all call for papers about `r round(abs(days_allowed[, mean(total)]), -1)` days before the conference.
Perth 2013 was an outlier, starting earlier, running longer and
with an extension period about twice that of other conferences.
This was done to maximise the number of ~~income generating units~~ attendees.

There were plenty of papers at each conference. 
```{r}
# How many papers in each status group, by conference
tbl <- dcast(SUBS, value.var = "n", conference~status, fun = sum)
# and add the sum of all papers, per conference
tbl[, total:=base::sum(.SD), by=conference]
# make in year order
tbl <- tbl[order(-str_extract(conference, "_(.*)")),] 
print(tbl[, total, by=conference])
```
Perth 2019 is a monster with the assistance of AOCMP, weighing in at `r tbl[conference %like% 2019, sum(total)]` papers in total.

Hobart in 2017 looks a bit light on, but this may be due to some late submissions 
being missed[^2^].

Perth 2019 is a monster with the assistance of AOCMP.

# what themes abounded?

Only the two Perth meetings have submission details. These were grouped by broad themes to allow comparison.
```{r }
details <- data.table(file = dir(path = clean_path, 
                                 pattern = "details.csv", 
                                 full.names = TRUE)
)
details[, year := str_match(file, "\\_(\\d{4})\\_")[,2]]
PER <- details[, fread(file), by=year]

# Make some broad classes of submission, based on which theme was chosen
PER[theme %like% "Radiology", topic := "Radiology"]
PER[theme %like% "ROMP|Radiotherapy", topic := "ROMP"]
PER[theme %like% "Nuclear Med", topic := "Nuc Med"]
PER[theme %like% "Health Phys", topic := "Health Phys"]
PER[theme %like% "Engineer", topic := "Eng"]
# A catch-all for the rest
PER[is.na(topic), topic := "other"]
# Two conferences in Perth this year, so label by meeting to tell them apart
PER[, meeting := paste(conference, year)]

# Calculate percentages by first getting the total count per meeting
# then dividing the count per topic by that total
numbers <- PER[, .N, by = "topic,meeting"]
numbers <- numbers[, .(topic, percent = 100*(N/sum(N))), by=meeting]

ggplot(numbers) + aes(x = meeting, y = percent, fill = topic) + geom_col()
```

The percentage of abstracts in each discipline seems fairly stable over time, although EPSM 2013 had a higher proportion of ROMP and Engineering related content and less Nuclear Medcine or Health Physics. The number of Engineering abstracts may have been because the Engineers on the conference committee actively extorted submissions.
```{r }
print(dcast(numbers, topic~meeting)[, lapply(.SD, round, 2), by = topic])
```

AOCMP members seem less interested in Radiology Physics, with a lot more 'other' abstracts.
This may be partly an artefact of the wide range of themes in 2019.

No-one seems to love Health Physics, which is sad.



How about a neat table of data? See, Table \@ref(tab:iristable):

```{r, iristable}
knitr::kable(
  iris[1:15,1:5], format = "html",
  caption = "A table made with the **knitr::kable** function.",
  align = "c", col.names = c("Sepal <br> Length",
                             "Sepal <br> Width",
                             "Petal <br> Length",
                             "Petal <br> Width",
                             "Species"),
  escape = FALSE)
```

# embrace & extend

To add another conference to this study, several steps

1. add the relevant dates to conf.dates.csv

This has one row for each meeting, with six columns

name     | type | contents
----     | ---- | ---------- 
city     | string | the name of the city where the conference was held
year     | YYYY | a four digit year
date     | YYYY-MM-DD | the date the meeting starts, in ISO format
call     | YYYY-MM-DD | when the call for papers went out, in ISO format 
close    | YYYY-MM-DD | when submissions closed, in ISO format
extended | YYYY-MM-DD | when they *really* closed, in ISO format

Note that for 2019 there were two meetings in the one city, so AOCMP became a city.


# References

# Colophon

This poster was made with the `posterdown_betterport` template for the {posterdown} [package](https://github.com/brentthorne/posterdown), in an attempt to sell the idea of Reproduceable Research.

The complete package, including the cleaned data and all the poster templates




I was inspired by the twitter thread of [Mike Morrison](https://mobile.twitter.com/mikemorrison/status/1110191245035479041) and wanted to apply the `#betterposter` concept to the reproducible (yet simple to use) functionality of the {posterdown}